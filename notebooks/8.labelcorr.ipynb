{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caff14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Ready to find potential mislabels.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "from datasets import Dataset\n",
    "import demoji\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# IMPORTANT: Update this path to the final checkpoint of your best run\n",
    "BEST_MODEL_PATH = './results/final_tune_random_deletion/checkpoint-505' #<-- CHECK AND UPDATE THIS!\n",
    "FRIENDS_DATA_PATH = '../data/data1.xlsx'\n",
    "OUTPUT_CORRECTION_FILE = 'label_correction_sheet.xlsx'\n",
    "\n",
    "print(\"Configuration loaded. Ready to find potential mislabels.\")\n",
    "# Tip: To find the checkpoint number, look inside the 'final_tune_random_deletion' folder.\n",
    "# It's usually the folder with the highest number, e.g., 'checkpoint-235'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bafa7574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./results/final_tune_random_deletion/checkpoint-505\n",
      "Loading data from: ../data/data1.xlsx\n",
      "Loaded 1001 unique entries to review.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Model and Full Dataset\n",
    "\n",
    "print(f\"Loading model from: {BEST_MODEL_PATH}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BEST_MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_PATH)\n",
    "trainer = Trainer(model=model) # A simple trainer for running predictions\n",
    "\n",
    "print(f\"Loading data from: {FRIENDS_DATA_PATH}\")\n",
    "# Load the ENTIRE friends dataset\n",
    "review_df = pd.read_excel(FRIENDS_DATA_PATH)\n",
    "\n",
    "# --- Data Cleaning (must be identical to your training script) ---\n",
    "# Standardize columns\n",
    "review_df.columns = [col.strip().lower() for col in review_df.columns]\n",
    "if 'entry' in review_df.columns:\n",
    "    review_df.rename(columns={'entry': 'text'}, inplace=True)\n",
    "\n",
    "# Drop rows with missing text or emotion, and duplicates\n",
    "review_df.dropna(subset=['text', 'emotion'], inplace=True)\n",
    "review_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "review_df = review_df.reset_index(drop=True) # Reset index for clean processing\n",
    "\n",
    "print(f\"Loaded {len(review_df)} unique entries to review.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847de564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\das99\\AppData\\Local\\Temp\\ipykernel_5984\\3596445738.py:10: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing and tokenizing all entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1001/1001 [00:00<00:00, 1836.78 examples/s]\n",
      "Map: 100%|██████████| 1001/1001 [00:00<00:00, 16964.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model to get predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:04<00:00, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### **Cell 3: Preprocess Data and Get Model Predictions**\n",
    "\n",
    "\n",
    "# Cell 3: Preprocess Data and Get Model Predictions\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "review_ds = Dataset.from_pandas(review_df)\n",
    "\n",
    "# --- Preprocessing (identical to your training script) ---\n",
    "demoji.download_codes()\n",
    "def preprocess_for_prediction(batch):\n",
    "    # Only run demoji conversion\n",
    "    batch['text'] = [demoji.replace_with_desc(str(text), sep=\" \") for text in batch['text']]\n",
    "    return batch\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    # Just tokenize the text\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "print(\"Preprocessing and tokenizing all entries...\")\n",
    "review_ds = review_ds.map(preprocess_for_prediction, batched=True)\n",
    "tokenized_review_ds = review_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "print(\"Running model to get predictions...\")\n",
    "predictions = trainer.predict(tokenized_review_ds)\n",
    "\n",
    "# Get the predicted label index and the raw logits\n",
    "predicted_indices = np.argmax(predictions.predictions, axis=1)\n",
    "logits = torch.from_numpy(predictions.predictions)\n",
    "\n",
    "# Get the confidence score (softmax probability) for the predicted class\n",
    "confidence_scores = F.softmax(logits, dim=1).max(dim=1).values.numpy()\n",
    "\n",
    "# Convert predicted indices back to string labels\n",
    "predicted_labels = [model.config.id2label[i] for i in predicted_indices]\n",
    "\n",
    "print(\"Prediction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e623e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SURGICAL LABEL CORRECTION SHEET ---\n",
      "Found 61 potential mislabels.\n",
      "Saved them to 'label_correction_sheet.xlsx' for your review.\n",
      "\n",
      "--- Top 20 Candidates for Review (Most Confident Model Suggestions) ---\n",
      "                                                  text  emotion  \\\n",
      "371  They changed the app again, and now nothin' wo...    Anger   \n",
      "78   Everyone was speaking, and for some reason, th...  Disgust   \n",
      "521  All my life I've seen my friends lead a chill ...  Disgust   \n",
      "584  Practised Kerala entrance biology diagrams, co...      Joy   \n",
      "593  Realised I haven’t touched English literature ...     Fear   \n",
      "107           Saw my childhood pics and felt nostalgic      Joy   \n",
      "72   Yesterday Virat retired and today the Warriors...  Sadness   \n",
      "526  Blank on Article 32 in Polity viva. Switching ...    Anger   \n",
      "261  Mid-sem blues: Indian Economy presentation oka...    Anger   \n",
      "139  We never started as strangers, but we kept it ...  Sadness   \n",
      "432  The fan is humming, kinda annoying but also co...  Neutral   \n",
      "39   I’m feeling unsatisfied as I have a lot on my ...     Fear   \n",
      "999  Girlfriend and I are on a break. We both have ...  Neutral   \n",
      "513  My dinner plan totally went bad. Now I'm just ...    Anger   \n",
      "773  Ugh, the surprise scholarship shortlist was su...      Joy   \n",
      "260  Spent 4 h on coordinate geometry, still lost. ...  Sadness   \n",
      "101  Going through functional depression. Ensuring ...  Neutral   \n",
      "925  Met a guy from a dating app—it was actually cu...      Joy   \n",
      "165     Senior suggested iCall for anxiety, might try.  Sadness   \n",
      "265  GATE form filled but specialisation dilemma (E...  Disgust   \n",
      "\n",
      "    model_suggestion  confidence human_corrected_label  \n",
      "371          Disgust    0.998827                        \n",
      "78             Anger    0.998566                        \n",
      "521            Anger    0.998412                        \n",
      "584          Neutral    0.998376                        \n",
      "593          Neutral    0.998166                        \n",
      "107          Neutral    0.998148                        \n",
      "72             Anger    0.998124                        \n",
      "526              Joy    0.997862                        \n",
      "261          Neutral    0.997836                        \n",
      "139              Joy    0.997785                        \n",
      "432          Disgust    0.997425                        \n",
      "39           Sadness    0.996916                        \n",
      "999          Sadness    0.996880                        \n",
      "513          Sadness    0.996789                        \n",
      "773             Fear    0.996767                        \n",
      "260             Fear    0.996724                        \n",
      "101          Sadness    0.996588                        \n",
      "925             Fear    0.996219                        \n",
      "165             Fear    0.996057                        \n",
      "265             Fear    0.995983                        \n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Generate and Save the Correction Sheet\n",
    "\n",
    "# Add the new information to our DataFrame\n",
    "review_df['model_suggestion'] = predicted_labels\n",
    "review_df['confidence'] = confidence_scores\n",
    "\n",
    "# Filter to find only the entries where the model disagrees with the original label\n",
    "disagreements_df = review_df[review_df['emotion'] != review_df['model_suggestion']].copy()\n",
    "\n",
    "# Sort by the model's confidence in its suggestion (highest confidence first)\n",
    "# These are the most likely candidates for an incorrect original label.\n",
    "disagreements_df = disagreements_df.sort_values(by='confidence', ascending=False)\n",
    "\n",
    "# Add a blank column for your final decision\n",
    "disagreements_df['human_corrected_label'] = ''\n",
    "\n",
    "# Reorder columns for clarity\n",
    "final_sheet = disagreements_df[['text', 'emotion', 'model_suggestion', 'confidence', 'human_corrected_label']]\n",
    "\n",
    "# Save the candidates to an Excel file\n",
    "final_sheet.to_excel(OUTPUT_CORRECTION_FILE, index=False)\n",
    "\n",
    "print(f\"\\n--- SURGICAL LABEL CORRECTION SHEET ---\")\n",
    "print(f\"Found {len(final_sheet)} potential mislabels.\")\n",
    "print(f\"Saved them to '{OUTPUT_CORRECTION_FILE}' for your review.\")\n",
    "print(\"\\n--- Top 20 Candidates for Review (Most Confident Model Suggestions) ---\")\n",
    "print(final_sheet.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28504397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-lab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
